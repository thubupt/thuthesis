\chapter{LDoS攻击原理与模型介绍}
\label{cha:LDoS}

本章的主要内容是对LDoS攻击进行探讨。首先对TCP拥塞控制机制和LDoS攻击原理进行说明。接下来，对LDoS攻击的特征进行分析与说明。最后，对LDoS攻击的各类攻击模型进行分析和探讨。

\section{LDoS攻击原理}
\label{chap3:LDoSstate}

\subsection{TCP拥塞控制机制}

对于任何基于TCP协议的数据流，都需要TCP拥塞控制机制，因为该机制可以对网络进行有效的调节。在网络中，所有的流都想让自己的数据尽快的传输，但是，所有流尽可能传输的结果就可能造成路由器或者链路的负载过大，引发网络拥塞，所有流都无法传输数据。因此，网络拥塞控制对于网络是必不可少的，而TCP拥塞控制为了给TCP流争提供合适的竞争方式。

TCP拥塞控制在TCP协议中实现，在传输层实现。TCP拥塞控制机制也并非一成不变的，针对不同的场景，TCP拥塞控制的策略也会不同，很多研究对TCP拥塞控制机制进行了探索。

最早的拥塞控制机制是1988年由Jacobson.V\cite{Jacobson1988Congestion}提出的TCP Reno版本，该方案的主要是由慢启动、拥塞避免、快重传和快恢复四个部分组成，大部分的拥塞控制方案都是以该方案作为基础进行提升的，由于该方案设计的时候有些方面未曾考虑，因此，该方案适用于低延迟、低带宽的网络。
在1994年由O’Malley.S.W\cite{O1994TCP}提出的TCP Vegas版本，该方案通过RTT来精准的预测带宽的变化，判断网络的可用带宽。不过，该方案适用于只存在这一种算法的时候。
在2008年，由Ha.S\cite{Ha2008CUBIC}提出的TCP Cubic方案，该方案使用立方函数作为拥塞窗口的增长函数，因此能够在不出现丢包的情况下，保持自己的传输速率。该方案能够尽可能的利用网络剩余带宽，适用于高带宽、丢包少的网络。
2017年由Cardwell.N\cite{Cardwell2017BBR}提出的TCP BBR版本，该算法在谷歌使用之后，极大的提升了数据传输性能。该算法认为当网络中的数据包总量高于网络中可存放数据包总量的时候会产生拥塞，就会限制窗口，因此，在带宽高、延迟高还有一定丢包率的情况下，降低时延并且保证带宽。
此外，2013年由Winstein.K\cite{Winstein2013Remy}提出的Remy算法采用机器学习的方式生成拥塞控制模型。因此，该算法适用于挽留过复杂的网络环境。

拥塞控制机制并非一成不变的，不同的方案有不同的适应场景，但是，这些方案都遵循着超时重传机制（Retransmission Timeout, RTO）