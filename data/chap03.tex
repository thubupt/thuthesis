\chapter{LDoS攻击原理与模型介绍}
\label{cha:LDoS}

本章的主要内容是对LDoS攻击进行探讨。首先对LDoS攻击原理进行说明。接下来，对LDoS攻击的特征进行分析与说明。最后，对LDoS攻击的各类攻击模型进行分析和探讨。

\section{LDoS攻击原理}
\label{chap3:LDoSstate}

\subsection{TCP拥塞控制机制和超时重传机制}

此部分的主要内容为分析传输控制协议（Transmission Control Protocol,TCP）的拥塞控制机制与超时重传机制。首先讨论了不同时期提出的TCP拥塞控制机制，然后对超时重传机制（Retransmission Time Out, RTO）进行分析，探讨超时重传机制对TCP流的影响。

TCP协议是保证数据可靠的协议。对于任何基于TCP协议的数据流，都需要TCP拥塞控制机制，因为该机制可以对网络进行有效的调节。在网络中，所有的流都想让自己的数据尽快的传输，但是，所有流尽可能传输的结果就可能造成路由器或者链路的负载过大，引发网络拥塞，所有流都无法传输数据。因此，网络拥塞控制对于网络是必不可少的，而TCP拥塞控制为了给TCP流争提供合适的竞争方式。

TCP拥塞控制在TCP协议中实现，在传输层实现。TCP拥塞控制机制也并非一成不变的，针对不同的场景，TCP拥塞控制的策略也会不同，很多研究对TCP拥塞控制机制进行了探索。

最早的拥塞控制机制是1988年由Jacobson.V\cite{Jacobson1988Congestion}提出的TCP Reno版本，该方案的主要是由慢启动、拥塞避免、快重传和快恢复四个部分组成，大部分的拥塞控制方案都是以该方案作为基础进行提升的，由于该方案设计的时候有些方面未曾考虑，因此，该方案适用于低延迟、低带宽的网络。
在1994年由O’Malley.S.W\cite{O1994TCP}提出的TCP Vegas版本，该方案通过RTT来精准的预测带宽的变化，判断网络的可用带宽。不过，该方案适用于只存在这一种算法的时候。
在2008年，由Ha.S\cite{Ha2008CUBIC}提出的TCP Cubic方案，该方案使用立方函数作为拥塞窗口的增长函数，因此能够在不出现丢包的情况下，保持自己的传输速率。该方案能够尽可能的利用网络剩余带宽，适用于高带宽、丢包少的网络。
2017年由Cardwell.N\cite{Cardwell2017BBR}提出的TCP BBR版本，该算法在谷歌使用之后，极大的提升了数据传输性能。该算法认为当网络中的数据包总量高于网络中可存放数据包总量的时候会产生拥塞，就会限制窗口，因此，在带宽高、延迟高还有一定丢包率的情况下，降低时延并且保证带宽。
此外，2013年由Winstein.K\cite{Winstein2013Remy}提出的Remy算法采用机器学习的方式生成拥塞控制模型。因此，该算法适用于挽留过复杂的网络环境。

拥塞控制机制并非一成不变的，不同的方案有不同的适应场景，但是，这些方案都遵循着超时重传机制。在网络极其拥塞的情况下，TCP协议的发送端与接收端都收不到数据包，此时为了保证数据稳定的传输，TCP协议的发送端会进入指数退避阶段，将发送窗口改为1，避免网络进一步拥塞。在超时重传机制中，TCP流依靠RTO计时器来不定期探测网络拥塞状况。在TCP协议运行的过程中，RTO计时器中的值是由根据RTT实时计算得到的。

TCP的发送端维持两个两个变量，平滑往返时间（Smoothed Round-Trip Time, SRTT）和往返时间变化量（Round-Trip Time VARiation, RTTVAR）。根据RFC2988\cite{2000Computing}的设定，RTO的实时计算结果与SRTT、RTTVAR两个变量相关。当TCP的发送端与接收端完成一次测量RTT之后，发送端将RTO计时器设置为3秒。
当第一次测量获得的RTT，$R'$,主机设置SRTT = $R'$，RTTVAR = $R' / 2$，RTO = SRTT + max(G, 4RTTVAR)，此处的G被标记为时钟粒度（一般情况下，$\leq$100毫秒）。当获得一个RTT的值$R'$之后，RTTVAR和SRTT的计算公式如下：


\begin{center}
    RTTVAR = (1 - $\beta$) RTTVAR + $\beta$ |SRTT - $R'$|
\vspace{-0.1in}
\end{center}

\begin{center}
    SRTT = (1 - $\alpha$) SRTT + $\alpha R'$
\end{center}

其中，有文献\cite{Jacobson1988Congestion}推荐设置$\alpha$ = 1/8， $\beta$ = 1/4。


通过对RTTVAR和SRTT进行跟新之后，TCP发送端RTO的计算公式如下：
\begin{center}
    RTO = max(minRTO, SRTT + max(G,4 RTTVAR)).
\end{center}

在Linux系统中，一般讲RTO计时器的最小值(minRTO)设置为200毫秒,因此，在推荐的参数中，延迟低的网络RTO基本是200毫秒。

接下来，对超时重传管理机制通过RTO计时器进行控制的流程进行分析。若是在某一时刻$t_0$，一个序号为$n$的数据包有TCP的发送端发送，此时一个初始值设为200毫秒的RTO计时器开始计时，如果$n$号的数据包丢失了或者说接收端重复发送的三个ACK包都没被发送包接收。当RTO计时器算到200毫秒的时候，则这个流就会被认为超时。此时，发送端进入指数退避阶段，发送端将拥塞控制的窗口置为1，并且让RTO计时器的值加倍，变为400毫秒，重传序号为$n$的未曾接收到ACK的数据包，并且重置RTO计时器为新的RTO的值。

若是序号为$n$的数据包再次丢失，则发送端持续保持，发送端将保持在指数退避阶段，而RTO计时器将会等待400毫秒。也就是说在$t_0 + 600ms$的时候，RTO的值将被设为800毫秒，并重复此过程。

若是序号为$n$的数据包的数据包成功的$t_0 + 200ms$之前接收到该数据包，例如在$t$+ RTT的时刻接收到$n$号数据包，则TCP发送端退出指数退避阶段并将RTO的值置为200毫秒，又开始正常的传输。

\subsection{LDoS攻击原理}
此部分的主要内容为LDoS攻击原理进行分析，讲述如何利用TCP的超时重传机制对来实现DoS攻击，即LDoS攻击。接下来，我们提供了LDoS的实现模型，并且讨论LDoS的变种攻击的威力。


